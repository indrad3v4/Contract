[W&B Fully Connected](https://wandb.ai/fully-connected)

>

[Articles](https://wandb.ai/fully-connected)

# o3 model Python quickstart using the OpenAI API

Get set up and running the new o3hmini models in Python using the OpenAI API quickly and easily in this tutorial.

[Dave Davies](https://wandb.ai/ml-reports)

Share

Comment
1 star

Created on January 31\|Last edited on January 31

Comment

Getting started with OpenAI's new [o3 models](https://wandb.ai/byyoung3/private_mlnews/reports/o3-mini-vs-DeepSeek-R1-API-setup-performance-testing-model-evaluation--VmlldzoxMTEzNjM4Nw) via the API is straightforward, offering flexibility beyond what’s available in the ChatGPT interface or [GPT-4o](https://wandb.ai/onlineinference/gpt-python/reports/GPT-4o-Python-quickstart-using-the-OpenAI-API--VmlldzozODI1MjY4). This quickstart guide will have you up and running in about 5 minutes.

If you want to jump right in, there's also a Colab to go with it:

[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1J0_UVhJ5VTzgie6KQ9p0ilBrc1MzJdV6?usp=sharing)

﻿

Here's what we're covering in this tutorial:

#### Table Of Contents

[What is o3 and how does it differ from other OpenAI models?](https://wandb.ai/onlineinference/gpt-python/reports/o3-model-Python-quickstart-using-the-OpenAI-API--VmlldzoxMTE2NTQxNw?utm_source=chatgpt.com#what-is-o3-and-how-does-it-differ-from-other-openai-models?) [The key upgrades from o1](https://wandb.ai/onlineinference/gpt-python/reports/o3-model-Python-quickstart-using-the-OpenAI-API--VmlldzoxMTE2NTQxNw?utm_source=chatgpt.com#the-key-upgrades-from-o1) [W&B Weave](https://wandb.ai/onlineinference/gpt-python/reports/o3-model-Python-quickstart-using-the-OpenAI-API--VmlldzoxMTE2NTQxNw?utm_source=chatgpt.com#w&b-weave) [o3 models in Python quickstart](https://wandb.ai/onlineinference/gpt-python/reports/o3-model-Python-quickstart-using-the-OpenAI-API--VmlldzoxMTE2NTQxNw?utm_source=chatgpt.com#o3-models-in-python-quickstart) [Step 1: The OpenAI o1-mini API key](https://wandb.ai/onlineinference/gpt-python/reports/o3-model-Python-quickstart-using-the-OpenAI-API--VmlldzoxMTE2NTQxNw?utm_source=chatgpt.com#step-1:-the-openai-o1-mini-api-key) [Step 2: Installing OpenAI and W&B Weave](https://wandb.ai/onlineinference/gpt-python/reports/o3-model-Python-quickstart-using-the-OpenAI-API--VmlldzoxMTE2NTQxNw?utm_source=chatgpt.com#step-2:-installing-openai-and-w&b-weave) [Step 3: Import libraries and pass the OpenAI API key](https://wandb.ai/onlineinference/gpt-python/reports/o3-model-Python-quickstart-using-the-OpenAI-API--VmlldzoxMTE2NTQxNw?utm_source=chatgpt.com#step-3:-import-libraries-and-pass-the-openai-api-key) [Step 4: Configuring your o3 prompt](https://wandb.ai/onlineinference/gpt-python/reports/o3-model-Python-quickstart-using-the-OpenAI-API--VmlldzoxMTE2NTQxNw?utm_source=chatgpt.com#step-4:-configuring-your-o3-prompt) [Step 5: Generating content with the o3 models](https://wandb.ai/onlineinference/gpt-python/reports/o3-model-Python-quickstart-using-the-OpenAI-API--VmlldzoxMTE2NTQxNw?utm_source=chatgpt.com#step-5:-generating-content-with-the-o3-models) [Viewing your o3 model output in W&B Weave](https://wandb.ai/onlineinference/gpt-python/reports/o3-model-Python-quickstart-using-the-OpenAI-API--VmlldzoxMTE2NTQxNw?utm_source=chatgpt.com#viewing-your-o3-model-output-in-w&b-weave) [Related reading](https://wandb.ai/onlineinference/gpt-python/reports/o3-model-Python-quickstart-using-the-OpenAI-API--VmlldzoxMTE2NTQxNw?utm_source=chatgpt.com#related-reading)

﻿

﻿

If you're just getting started and don't yet have your machine set up to run Python, we've created a quick tutorial [here](https://wandb.ai/onlineinference/beginner-ml/reports/Beginner-ML-Installing-Acaconda-Jupyter-Notebook---Vmlldzo0MDc4NDkw) that will have you up and running in just a few minutes.

﻿

Additionally, if you need a walkthrough on getting the OpenAI API, you'll find that [here](https://wandb.ai/onlineinference/gpt-python/reports/GPT-4-in-Python-quickstart-using-the-OpenAI-API--VmlldzozODI1MjY4#getting-your-openai-api).

💡

Let's start with why the core question:

## What is o3 and how does it differ from other OpenAI models?

OpenAI o3-mini is the latest reasoning model from the folks at OpenAI's and excels at STEM applications (science, technology, engineering and mathematics). This model builds on the capabilities of o1-mini, but brings superior speed, accuracy, and reasoning ability while maintaining low latency and cost-effectiveness.

![](https://api.wandb.ai/files/onlineinference/images/projects/37393998/75113bf0.png)

﻿ [Source](https://openai.com/index/openai-o3-mini/) ﻿

### The key upgrades from o1

Performance: o3-mini matches exceeds o1-mini in reasoning tasks, with expert evaluations showing a 39% reduction in major errors.

Developer features: It introduces function calling, structured outputs, and developer messages to a mini reasoning model, making it production-ready from launch.

Reasoning effort options: Perhaps one of the best features (IMO) that that like o1, users can optimize between low, medium, and high reasoning effort to balance speed and accuracy.

Availability: o3-mini is available in the Chat Completions API, Assistants API, and Batch API, with access for Tier 3-5 API users - as opposed to only tier 5 for o1.

ChatGPT integration: o3-mini replaces o1-mini in ChatGPT for Plus, Team, and Pro users, increasing message rate limits significantly.

Pricing: o3-mini is priced significantly lower than o1.

![](https://api.wandb.ai/files/onlineinference/images/projects/37393998/eb6fd0ac.png)

﻿ [Source](https://openai.com/api/pricing/) ﻿

A notable miss is that unlike o1, o3-mini does not support visual reasoning.

Overall, it's a strong step forward giving users greater access—and at a cheaper rate.

## W&B Weave

If you'd like to build with o3, you'll need tools and [W&B Weave](https://wandb.ai/site/weave) simplifies the process of tracking and analyzing model outputs.

To get started, you'll import and initialize it with your project name. We recommend using the @weave.op decorator, which allows Weave to automatically log a function’s inputs and outputs. This makes tracking your model interactions seamless. Once your script runs, you’ll find detailed visualizations and traces in the Weave dashboard, making debugging and model refinement easier. [Our docs are a good place to get started](https://weave-docs.wandb.ai/).

## o3 models in Python quickstart

This tutorial assumes you're working in a Jupyter notebook but of course, the code will work in other applications. We're going to be working with the o1-mini model. And without further ado, let's jump right in.

Note: Okay. A little further ado, sorry. When you execute the cells below, you'll notice an asterisk (\[\*\]) appear between the brackets \[ \]. This indicates that the cell is running, and you’ll need to wait until the asterisk turns into a number before proceeding.

💡

### Step 1: The OpenAI o1-mini API key

First, set up your o3-preview API key:

```

%env OPENAI_API_KEY=KEY
```

(You'll want to replace KEY with your OpenAI API key.)

When you run the cell you'll get your key back as the output. This confirms that it's been successfully entered as an environment variable.

![](https://api.wandb.ai/files/onlineinference/images/projects/37393998/f9152d67.png)

﻿

### Step 2: Installing OpenAI and W&B Weave

To get started with the o1-preview model, all you need to install is OpenAI. However, we’ll also show you how to simplify reviewing multiple outputs using W&B Weave, which makes the process much more efficient. [﻿](https://wandb.ai/site/tables) ﻿

> This is a great time to [sign up for Weights & Biases](https://app.wandb.ai/login?signup=true&_gl=1*1mafv2r*_ga*NTI4NDY4NzQ2LjE2ODA3NDkzMDk.*_ga_JH1SJHJQXJ*MTY4MTY2NzU3Ni44LjEuMTY4MTY2ODk0Ny40NS4wLjA.), if you haven't already. This will save you from interrupting your workflow later.

The code to do this is:

```

!pip install openai weave
```

Run the Jupyter cell after entering this code.

![](https://api.wandb.ai/files/onlineinference/images/projects/37393998/2dc4ac70.png)

﻿

Now you've installed it, we still need to import it for use.

If you're new to Python, think of it this way: Installing a library is like uploading an image to a server—you’ve got the resource. Importing is like embedding that image on a webpage, making it accessible in your code.

💡

### Step 3: Import libraries and pass the OpenAI API key

In this block, we'll import the OpenAI and W&B Weave libraries we've already installed. We're also importing os and re to give us access to regular expressions and os to fetch environment variables (in this case, the OpenAI API).

```

import os
import weave
from openai import OpenAI
import re
﻿

# Initialize Weave and W&B
weave.init('o3-mini')
﻿

# Initialize OpenAI client
client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
```

In the line: weave.init('o3-mini')

You can change o3-mini to whatever you would like. This is going to be the project name inside Weights & Biases.

### Step 4: Configuring your o3 prompt

The following code will generate inputs you can fill in as they run. They will ask for:

Who the model should act as. This ties to the assistant role, and is used to define traits the o3 model should take on.

The prompt of what they should do. This ties to the user role, and is used to define what's expected from them. This is akin to what you would enter into the ChatGPT interface.

```

o3_assistant_prompt = "You are a " + input("Who should I be, as I answer your prompt?")
o3_user_prompt = input("What prompt do you want me to complete?")
o3_prompt = o3_assistant_prompt, o3_user_prompt
print(o3_prompt)
```

### Step 5: Generating content with the o3 models

Hopefully, this hasn't been too painful because now we're at the fun part.

Now that we’ve set everything up, it’s time to generate content.

The function below requests a response from the o3-mini model based on the provided prompt and logs the interaction in Weave:

The code defaults to using a high reasoning effort, since I'm moving the content burden onto GPT-4, but it can be adjusted to low or medium.

```

@weave.op()
def generate_content(o3_assistant_prompt: str, o3_user_prompt: str) -> str:
    prompt = f"{o3_assistant_prompt}\nUser request: {o3_user_prompt}"
    messages = [\
        {"role": "assistant", "content": o3_assistant_prompt},\
        {"role": "user", "content": o3_user_prompt}\
    ]
    response = client.chat.completions.create(
        model="o3-mini",
        messages=messages,
        reasoning_effort="high"  # This can be set to low, medium or high.
    )
    return response.choices[0].message.content
﻿

# Generate content using the provided assistant and user prompts
content = generate_content(o3_assistant_prompt, o3_user_prompt)
﻿

# Print the generated response
print(content)
```

When run, these appear as:

![](https://api.wandb.ai/files/onlineinference/images/projects/37393998/2483cbe5.png)

﻿

## Viewing your o3 model output in W&B Weave

This proved especially important while writing this article.

When writing [the quickstart for the o1 model](https://wandb.ai/onlineinference/gpt-python/reports/o1-preview-Python-quickstart-using-the-OpenAI-API--Vmlldzo5Mzk4Mjc0), the model would send reasoning steps back through the API. They weren't necessarily the literal steps, but we could ask the o1 models to send steps back. This article was going to initially use o3 to generate the steps, and then GPT-4o for the content, but looking at the traces in Weave, we can see why this wouldn't produce the effect we'd want:

![](https://api.wandb.ai/files/onlineinference/images/projects/37393998/b629189f.png)

﻿

﻿

Worse, it will still try to produce the content requested, you simply may not know it's not based on reasoning.

When run through o1 only, we can see the trace:

![](https://api.wandb.ai/files/onlineinference/images/projects/37393998/a871b383.png)

﻿

﻿

Notwithstanding that it went a different direction than I intended with "o1" it did pretty well.

Hopefully you've found this o3 model quickstart tutorial helpful. Please drop in the comments what you end up working on!

## Related reading

[Getting set up and running GPT-4o on your machine in Python using the OpenAI API.](https://wandb.ai/onlineinference/gpt-python/reports/GPT-4o-Python-quickstart-using-the-OpenAI-API--VmlldzozODI1MjY4) [A quickstart tutorial on how to set up the Gemini 2.0 API with W&B logging in Python.](https://wandb.ai/onlineinference/Gemini/reports/The-Gemini-2-0-API-in-Python-quickstart-tutorial--Vmlldzo2MjU3OTQz?galleryTag=llm) [Getting set up and running the new o1 models in Python using the OpenAI API. We'll be working with o1-preview.](https://wandb.ai/onlineinference/gpt-python/reports/o1-model-Python-quickstart-using-the-OpenAI-API--Vmlldzo5Mzk4Mjc0)

﻿

﻿

Add a comment

Tags: [Articles](https://wandb.ai/fully-connected), [Weave](https://wandb.ai/fully-connected), [Experiment](https://wandb.ai/fully-connected/blog/experiment), [GenAI](https://wandb.ai/fully-connected/blog/generative-modeling)

[![](https://site.wandb.ai/wp-content/uploads/2025/06/Frame-1171275266.jpg)](https://wandb.ai/site/courses/agents/?utm_campaign=fc_banner)

Created with ❤️ on Weights & Biases.

[https://wandb.ai/onlineinference/gpt-python/reports/o3-model-Python-quickstart-using-the-OpenAI-API--VmlldzoxMTE2NTQxNw?utm\_source=chatgpt.com](https://wandb.ai/onlineinference/gpt-python/reports/o3-model-Python-quickstart-using-the-OpenAI-API--VmlldzoxMTE2NTQxNw?utm_source=chatgpt.com)

Made with Weights & Biases. [Sign up](https://wandb.ai/signup) or [log in](https://api.wandb.ai/oidc/login?) to create reports like this one.

Never lose track of another ML project. Try W&B today.

[Sign up](https://api.wandb.ai/oidc/login?signup=true) [Try W&B now](https://docs.wandb.ai/quickstart)

![Company Logo](https://cdn.cookielaw.org/logos/7ae3d8ca-f23a-4e50-a21c-edc54404815f/247bb628-f945-430d-a691-71470ed4595c/23d4561e-633b-46ba-844d-0eb603a26414/Weights_&_Biases_White_Text_(1).png)

## Privacy Preference Center

When you visit any website, it may store or retrieve information on your browser, mostly in the form of cookies. This information might be about you, your preferences or your device and is mostly used to make the site work as you expect it to. The information does not usually directly identify you, but it can give you a more personalized web experience. Because we respect your right to privacy, you can choose not to allow some types of cookies. Click on the different category headings to find out more and change our default settings. However, blocking some types of cookies may impact your experience of the site and the services we are able to offer.


[More information](https://cookiepedia.co.uk/giving-consent-to-cookies)

Allow All

### Manage Consent Preferences

#### Strictly Necessary Cookies

Always Active

These cookies are necessary for the website to function and cannot be switched off in our systems. They are usually only set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms. You can set your browser to block or alert you about these cookies, but some parts of the site will not then work. These cookies do not store any personally identifiable information.

#### Functional Cookies

Functional Cookies

These cookies enable the website to provide enhanced functionality and personalisation. They may be set by us or by third party providers whose services we have added to our pages. If you do not allow these cookies then some or all of these services may not function properly.

#### Targeting Cookies

Targeting Cookies

These cookies may be set through our site by our advertising partners. They may be used by those companies to build a profile of your interests and show you relevant adverts on other sites. They do not store directly personal information, but are based on uniquely identifying your browser and internet device. If you do not allow these cookies, you will experience less targeted advertising.

#### Performance Cookies

Performance Cookies

These cookies allow us to count visits and traffic sources so we can measure and improve the performance of our site. They help us to know which pages are the most and least popular and see how visitors move around the site. All information these cookies collect is aggregated and therefore anonymous. If you do not allow these cookies we will not know when you have visited our site, and will not be able to monitor its performance.

Back Button

### Cookie List

Search Icon

Filter Icon

Clear

checkbox labellabel

ApplyCancel

ConsentLeg.Interest

checkbox labellabel

checkbox labellabel

checkbox labellabel

Reject AllConfirm My Choices

[![Powered by Onetrust](https://cdn.cookielaw.org/logos/static/powered_by_logo.svg)](https://www.onetrust.com/products/cookie-consent/)

[iframe](about:blank)